{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMK3ulqzWyOdS6MnwsX42rN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"_TYFooO5Z7g2","executionInfo":{"status":"ok","timestamp":1705594662963,"user_tz":-330,"elapsed":3023,"user":{"displayName":"Akshat Chauhan","userId":"17341191293424364314"}}},"outputs":[],"source":["from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","source":["drive.mount(\"/content/drive/\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D4e0_SQraFNW","executionInfo":{"status":"ok","timestamp":1705594666619,"user_tz":-330,"elapsed":3663,"user":{"displayName":"Akshat Chauhan","userId":"17341191293424364314"}},"outputId":"aab52349-02b1-4e31-b678-8ef77b0a0fa3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["pip install mtcnn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKE0AtHhphqY","executionInfo":{"status":"ok","timestamp":1705594682353,"user_tz":-330,"elapsed":15739,"user":{"displayName":"Akshat Chauhan","userId":"17341191293424364314"}},"outputId":"e4868e64-ca25-43ac-837d-82907da28b49"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mtcnn in /usr/local/lib/python3.10/dist-packages (0.1.1)\n","Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (2.15.0)\n","Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (4.8.0.76)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.23.5)\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import random\n","from mtcnn import MTCNN"],"metadata":{"id":"UitMA0eLpgDC","executionInfo":{"status":"ok","timestamp":1705594695933,"user_tz":-330,"elapsed":13588,"user":{"displayName":"Akshat Chauhan","userId":"17341191293424364314"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# prompt: check if cuda is available\n","\n","import torch\n","print('Is CUDA available?', torch.cuda.is_available())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1mef7Z1qjtR","executionInfo":{"status":"ok","timestamp":1705594702835,"user_tz":-330,"elapsed":6907,"user":{"displayName":"Akshat Chauhan","userId":"17341191293424364314"}},"outputId":"88bb9eec-05bd-48c5-a7a6-9a36111d8b82"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Is CUDA available? False\n"]}]},{"cell_type":"code","source":["def extract_faces_from_all_frames(video_path, output_path,video, target_size=(224, 224)):\n","    # Open the video file\n","    video_capture = cv2.VideoCapture(video_path)\n","\n","    # Get the total number of frames in the video\n","    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    # Initialize MTCNN for face detection\n","    detector = MTCNN()\n","\n","    # Create output directory if it doesn't exist\n","    os.makedirs(output_path, exist_ok=True)\n","\n","    # Read and save faces from all frames\n","    for frame_index in range(total_frames):\n","        # Set the frame position\n","        video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n","\n","        # Read the frame\n","        ret, frame = video_capture.read()\n","\n","        # Detect faces in the frame\n","        faces = detector.detect_faces(frame)\n","\n","        # Save the detected faces as images\n","        for i, face in enumerate(faces):\n","            x, y, w, h = face['box']\n","            x, y = max(x, 0), max(y, 0)\n","            face_roi = frame[y:y+h, x:x+w]\n","\n","            # Resize the face to the target size\n","            resized_face = cv2.resize(face_roi, target_size)\n","\n","            # Save the resized face as an image\n","            face_filename = f\"{output_path}/{video}_face_{frame_index}_{i}.jpg\"\n","            cv2.imwrite(face_filename, resized_face)\n","\n","    # Release the video capture object\n","    video_capture.release()\n","def process_videos(input_folder, output_folder):\n","    # Iterating through videos\n","    os.makedirs(output_folder, exist_ok=True)\n","    videos = os.listdir(input_folder)\n","    videos=videos[170:]\n","    ctr = 170\n","    # Iterate through videos in the class folder\n","    for video in videos:\n","        video_file = os.path.join(input_folder, video)\n","        # Sample frames from the video and save them as a new video\n","        extract_faces_from_all_frames(video_file, output_folder,video)\n","        print(\"video \", ctr, \" done\")\n","        ctr+=1"],"metadata":{"id":"FbBe10axN5AK","executionInfo":{"status":"ok","timestamp":1705594702836,"user_tz":-330,"elapsed":8,"user":{"displayName":"Akshat Chauhan","userId":"17341191293424364314"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["pip install mediapipe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"01oAEoR--QJN","executionInfo":{"status":"ok","timestamp":1705594715838,"user_tz":-330,"elapsed":13009,"user":{"displayName":"Akshat Chauhan","userId":"17341191293424364314"}},"outputId":"9421e6f7-7a70-468c-d176-f4a4d3615426"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.9)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.5.26)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.23.5)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n","Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.6)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.47.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"]}]},{"cell_type":"code","source":["\n","import logging\n","import mediapipe as mp\n","\n","\n","# Set the logging level to suppress info messages from the mediapipe library\n","logging.getLogger('mediapipe').setLevel(logging.WARNING)\n","\n","def extract_faces_from_all_frames(video_path, output_path, video, target_size=(224, 224)):\n","    # Open the video file\n","    video_capture = cv2.VideoCapture(video_path)\n","\n","    # Get the total number of frames in the video\n","    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    # Initialize Mediapipe FaceDetection for ultra-fast face detection\n","    mp_face_detection = mp.solutions.face_detection\n","    face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.3)\n","\n","    # Create output directory if it doesn't exist\n","    os.makedirs(output_path, exist_ok=True)\n","\n","    # Read and save faces from all frames\n","\n","    frame_index=18\n","    video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n","\n","    # Read the frame\n","    ret, frame = video_capture.read()\n","\n","    # Convert the frame to RGB as mediapipe expects RGB input\n","    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","    # Detect faces in the frame\n","    results = face_detection.process(rgb_frame)\n","\n","    # Save the detected faces as images\n","    if results.detections:\n","        for i, detection in enumerate(results.detections):\n","            bboxC = detection.location_data.relative_bounding_box\n","            ih, iw, _ = frame.shape\n","            x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n","            face_roi = frame[y:y+h, x:x+w]\n","            if not face_roi.size:\n","                continue\n","\n","            # Resize the face to the target size\n","            resized_face = cv2.resize(face_roi, target_size)\n","\n","            # Save the resized face as an image\n","            face_filename = f\"{output_path}/{video}_face_{frame_index}_{i}.jpg\"\n","            cv2.imwrite(face_filename, resized_face)\n","\n","    # Release the video capture object\n","    video_capture.release()\n","\n","def process_videos(input_folder, output_folder):\n","    # Iterating through videos\n","    os.makedirs(output_folder, exist_ok=True)\n","    videos = os.listdir(input_folder)\n","    print(len(videos))\n","    ctr=1\n","    # Iterate through videos in the class folder\n","    for video in videos:\n","        video_file = os.path.join(input_folder, video)\n","        # Sample frames from the video and save them as a new video\n","        extract_faces_from_all_frames(video_file, output_folder, video)\n","        print(\"video \", ctr, \" done\")\n","        ctr += 1\n"],"metadata":{"id":"Aqa0nO0B-JQh","executionInfo":{"status":"ok","timestamp":1705595612618,"user_tz":-330,"elapsed":425,"user":{"displayName":"Akshat Chauhan","userId":"17341191293424364314"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["input_folder = \"/content/drive/MyDrive/Capstone/sampled-celeb-df/Fake\"\n","output_folder = \"/content/drive/MyDrive/Capstone/Images/Fake\"\n","process_videos(input_folder, output_folder)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Rhc3XTkMPar-","executionInfo":{"status":"error","timestamp":1705595868782,"user_tz":-330,"elapsed":113168,"user":{"displayName":"Akshat Chauhan","userId":"17341191293424364314"}},"outputId":"68e2c5fd-22f6-4140-e9f4-058fc15a8c90"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["5639\n","video  1  done\n","video  2  done\n","video  3  done\n","video  4  done\n","video  5  done\n","video  6  done\n","video  7  done\n","video  8  done\n","video  9  done\n","video  10  done\n","video  11  done\n","video  12  done\n","video  13  done\n","video  14  done\n","video  15  done\n","video  16  done\n","video  17  done\n","video  18  done\n","video  19  done\n","video  20  done\n","video  21  done\n","video  22  done\n","video  23  done\n","video  24  done\n","video  25  done\n","video  26  done\n","video  27  done\n","video  28  done\n","video  29  done\n","video  30  done\n","video  31  done\n","video  32  done\n","video  33  done\n","video  34  done\n","video  35  done\n","video  36  done\n","video  37  done\n","video  38  done\n","video  39  done\n","video  40  done\n","video  41  done\n","video  42  done\n","video  43  done\n","video  44  done\n","video  45  done\n","video  46  done\n","video  47  done\n","video  48  done\n","video  49  done\n","video  50  done\n","video  51  done\n","video  52  done\n","video  53  done\n","video  54  done\n","video  55  done\n","video  56  done\n","video  57  done\n"]},{"output_type":"error","ename":"error","evalue":"OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-07898d6a86ab>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Capstone/sampled-celeb-df/Fake\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Capstone/Images/Fake\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprocess_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-19-746a1a69b2a8>\u001b[0m in \u001b[0;36mprocess_videos\u001b[0;34m(input_folder, output_folder)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mvideo_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Sample frames from the video and save them as a new video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mextract_faces_from_all_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"video \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mctr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-746a1a69b2a8>\u001b[0m in \u001b[0;36mextract_faces_from_all_frames\u001b[0;34m(video_path, output_path, video, target_size)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Convert the frame to RGB as mediapipe expects RGB input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mrgb_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Detect faces in the frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"]}]},{"cell_type":"code","source":["# prompt: code to  count number of files in a folder\n","\n","!find /content/drive/MyDrive/Capstone/Images/Fake -type f | wc -l\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XQpuYR83aGEH","executionInfo":{"status":"ok","timestamp":1705595428707,"user_tz":-330,"elapsed":1151,"user":{"displayName":"Akshat Chauhan","userId":"17341191293424364314"}},"outputId":"97d56f45-04a8-4a78-f026-3eeefa009e57"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["16879\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"d4z-tTvyaOkV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example usage\n","input_directory = \"/content/drive/MyDrive/Capstone/sampled-celeb-df/Real\"\n","output_directory = \"/content/drive/MyDrive/Capstone/Images/Real\"\n","process_videos(input_directory, output_directory)"],"metadata":{"id":"vRRMmX_kPDAY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4q4isxPv0vn8"},"execution_count":null,"outputs":[]}]}