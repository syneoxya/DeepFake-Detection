{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import AutoImageProcessor, TFEfficientFormerModel,MobileViTV2Model,EfficientFormerModel\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNet,VGG16,ResNet50,EfficientNetB0\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"apple/mobilevitv2-1.0-imagenet1k-256\")\n",
    "model = MobileViTV2Model.from_pretrained(\"apple/mobilevitv2-1.0-imagenet1k-256\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"../Data/sampled_Faces/Frames\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path=dir+\"/frame_real\"\n",
    "fake_path=dir+\"/frame_fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir(real_path)))\n",
    "print(len(os.listdir(fake_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:/Users/Akshat/Desktop/Capstone/Data/sampled_Faces/Frames/frame_fake/0.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "device_name = torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "device_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=Image.open(path)\n",
    "inputs = image_processor(image, return_tensors=\"pt\").to('cuda')\n",
    "model.to('cuda')\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "features=outputs.last_hidden_state.cpu()\n",
    "features.shape\n",
    "global_avg_pooling_layer = nn.AdaptiveAvgPool2d(1)\n",
    "output = global_avg_pooling_layer(features)\n",
    "output = output.view(output.size(0), -1)\n",
    "output_numpy = output.detach().numpy()\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_avg_pooling_layer = nn.AdaptiveAvgPool2d(1)\n",
    "output = global_avg_pooling_layer(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.view(output.size(0), -1)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"../Data/Image_set2/Normal_images/train\"\n",
    "real_path=dir+\"/Real\"\n",
    "fake_path=dir+\"/Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path=dir+\"/Real\"\n",
    "fake_path=dir+\"/Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir(real_path)))\n",
    "print(len(os.listdir(fake_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15171+15079"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "else:\n",
    "    print(\"GPU is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.empty((0, 512), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(real_path):\n",
    "    img=Image.open(real_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool2d(1)\n",
    "    output = global_avg_pooling_layer(features).view(features.size(0), -1)\n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    # if(ctr%100==0):\n",
    "    print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(fake_path):\n",
    "    img=Image.open(fake_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool2d(1)\n",
    "    output = global_avg_pooling_layer(features).view(features.size(0), -1)\n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    # if(ctr%100==0):\n",
    "    print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "18407+15416\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(features_array)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "\n",
    "for i in range(30230):\n",
    "    if i<15179:\n",
    "        a.append(0)\n",
    "    else:\n",
    "        a.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"]=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Data/celebdfmobilevit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, ViTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=Image.open(path)\n",
    "inputs = image_processor(image, return_tensors=\"pt\").to('cuda')\n",
    "model.to('cuda')\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "features=outputs.last_hidden_state.cpu()\n",
    "features.shape\n",
    "global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "output = output.view(1, -1)\n",
    "output_numpy = output.detach().numpy()\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"../Data/Image_set2/Normal_images/train\"\n",
    "real_path=dir+\"/Real\"\n",
    "fake_path=dir+\"/Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.empty((0, 768), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(real_path):\n",
    "    img=Image.open(real_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    # if(ctr%100==0):\n",
    "    print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(fake_path):\n",
    "    img=Image.open(fake_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    # if(ctr%100==0):\n",
    "    print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(features_array)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "\n",
    "for i in range(30230):\n",
    "    if i<15179:\n",
    "        a.append(0)\n",
    "    else:\n",
    "        a.append(1)\n",
    "\n",
    "df['label']=a\n",
    "\n",
    "df.to_csv(\"../Data/celebdfvit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label']=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Data/celebdfvit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"../Data/sampled_Faces/Frames\"\n",
    "real_path=dir+\"/frame_real\"\n",
    "fake_path=dir+\"/frame_fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.empty((0, 768), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(real_path):\n",
    "    img=Image.open(real_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    # if(ctr%100==0):\n",
    "    print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(fake_path):\n",
    "    img=Image.open(fake_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    # if(ctr%100==0):\n",
    "    print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(features_array)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "\n",
    "for i in range(33823):\n",
    "    if i<15416:\n",
    "        a.append(0)\n",
    "    else:\n",
    "        a.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"]=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Data/ffvit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swin Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, Swinv2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swinv2-tiny-patch4-window8-256\")\n",
    "model = Swinv2Model.from_pretrained(\"microsoft/swinv2-tiny-patch4-window8-256\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.empty((0, 768), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(real_path):\n",
    "    img=Image.open(real_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    if(ctr%100==0):\n",
    "        print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(fake_path):\n",
    "    img=Image.open(fake_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    if(ctr%100==0):\n",
    "        print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(features_array)\n",
    "df.head()\n",
    "\n",
    "a=[]\n",
    "\n",
    "for i in range(33823):\n",
    "    if i<15416:\n",
    "        a.append(0)\n",
    "    else:\n",
    "        a.append(1)\n",
    "\n",
    "df[\"label\"]=a\n",
    "\n",
    "df.to_csv(\"../Data/ffswinv2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"../Data/Image_set2/Normal_images/train\"\n",
    "real_path=dir+\"/Real\"\n",
    "fake_path=dir+\"/Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.empty((0, 768), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(real_path):\n",
    "    img=Image.open(real_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    if(ctr%100==0):\n",
    "        print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(fake_path):\n",
    "    img=Image.open(fake_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    if(ctr%100==0):\n",
    "        print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(features_array)\n",
    "df.head()\n",
    "\n",
    "a=[]\n",
    "\n",
    "for i in range(30230):\n",
    "    if i<15179:\n",
    "        a.append(0)\n",
    "    else:\n",
    "        a.append(1)\n",
    "\n",
    "df[\"label\"]=a\n",
    "\n",
    "df.to_csv(\"../Data/celebdfswinv2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, LevitModel\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"facebook/levit-128S\")\n",
    "model = LevitModel.from_pretrained(\"facebook/levit-128S\")\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"../Data/sampled_Faces/ELA_Frames\"\n",
    "real_path=dir+\"/Real\"\n",
    "fake_path=dir+\"/Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.empty((0, 384), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"C:/Users/Akshat/Desktop/Capstone/Data/sampled_Faces/ELA_Frames/Fake/16.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=np.array(img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(real_path):\n",
    "    img=cv2.imread(real_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    if(ctr%100==0):\n",
    "        print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(fake_path):\n",
    "    img=cv2.imread(fake_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    if(ctr%100==0):\n",
    "        print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(real_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(fake_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15416+18407"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(features_array)\n",
    "df.head()\n",
    "\n",
    "a=[]\n",
    "\n",
    "for i in range(33823):\n",
    "    if i<15416:\n",
    "        a.append(0)\n",
    "    else:\n",
    "        a.append(1)\n",
    "\n",
    "df[\"label\"]=a\n",
    "\n",
    "df.to_csv(\"../Data/ffELAlevit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"../Data/Image_set2/ELA_images/train\"\n",
    "real_path=dir+\"/Real\"\n",
    "fake_path=dir+\"/Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir(real_path)))\n",
    "print(len(os.listdir(fake_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.empty((0, 384), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(real_path):\n",
    "    img=cv2.imread(real_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    if(ctr%100==0):\n",
    "        print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(fake_path):\n",
    "    img=cv2.imread(fake_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    if(ctr%100==0):\n",
    "        print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(features_array)\n",
    "df.head()\n",
    "\n",
    "a=[]\n",
    "\n",
    "for i in range(29737):\n",
    "    if i<14697:\n",
    "        a.append(0)\n",
    "    else:\n",
    "        a.append(1)\n",
    "\n",
    "df[\"label\"]=a\n",
    "\n",
    "df.to_csv(\"../Data/celebdfELALeViT.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swiftformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, SwiftFormerModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"MBZUAI/swiftformer-xs\")\n",
    "model = SwiftFormerModel.from_pretrained(\"MBZUAI/swiftformer-xs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.empty((0, 220), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path=\"../Data/sampled_Faces/Frames/frame_real\"\n",
    "fake_path=\"../Data/sampled_Faces/Frames/frame_fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(real_path):\n",
    "    img=Image.open(real_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool2d(1)  # Using AdaptiveAvgPool2d for 2D pooling\n",
    "    output = global_avg_pooling_layer(features).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    # if(ctr%100==0):\n",
    "    print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(fake_path):\n",
    "    img=Image.open(fake_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool2d(1)  # Using AdaptiveAvgPool2d for 2D pooling\n",
    "    output = global_avg_pooling_layer(features).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    # if(ctr%100==0):\n",
    "    print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(features_array)\n",
    "df.head()\n",
    "\n",
    "a=[]\n",
    "\n",
    "for i in range(33823):\n",
    "    if i<15416:\n",
    "        a.append(0)\n",
    "    else:\n",
    "        a.append(1)\n",
    "\n",
    "df[\"label\"]=a\n",
    "\n",
    "df.to_csv(\"../Data/ffswift.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.empty((0, 220), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "real_path=\"../Data/Image_set2/Normal_Images/train/Real\"\n",
    "fake_path=\"../Data/Image_set2/Normal_Images/train/Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(real_path):\n",
    "    img=Image.open(real_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool2d(1)  # Using AdaptiveAvgPool2d for 2D pooling\n",
    "    output = global_avg_pooling_layer(features).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    # if(ctr%100==0):\n",
    "    print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(fake_path):\n",
    "    img=Image.open(fake_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool2d(1)  # Using AdaptiveAvgPool2d for 2D pooling\n",
    "    output = global_avg_pooling_layer(features).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    # if(ctr%100==0):\n",
    "    print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(features_array)\n",
    "df.head()\n",
    "\n",
    "a=[]\n",
    "\n",
    "for i in range(30230):\n",
    "    if i<15179:\n",
    "        a.append(0)\n",
    "    else:\n",
    "        a.append(1)\n",
    "\n",
    "df[\"label\"]=a\n",
    "\n",
    "df.to_csv(\"../Data/celebdfswift.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EFFICIENT FORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"snap-research/efficientformer-l7-300\")\n",
    "model = EfficientFormerModel.from_pretrained(\"snap-research/efficientformer-l7-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=Image.open(path)\n",
    "inputs = image_processor(image, return_tensors=\"pt\").to('cuda')\n",
    "model.to('cuda')\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "features=outputs.last_hidden_state.cpu()\n",
    "features.shape\n",
    "global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "output = output.view(1, -1)\n",
    "output_numpy = output.detach().numpy()\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.empty((0, 768), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"../Data/Image_set2/Normal_images/train\"\n",
    "real_path=dir+\"/Real\"\n",
    "fake_path=dir+\"/Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(real_path):\n",
    "    img=Image.open(real_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    # if(ctr%100==0):\n",
    "    print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(fake_path):\n",
    "    img=Image.open(fake_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    # if(ctr%100==0):\n",
    "    print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(features_array)\n",
    "a=[]\n",
    "\n",
    "for i in range(30230):\n",
    "    if i<15179:\n",
    "        a.append(0)\n",
    "    else:\n",
    "        a.append(1)\n",
    "\n",
    "df['label']=a\n",
    "\n",
    "df.to_csv(\"../Data/celebdfEfficientFormer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"../Data/sampled_Faces/Frames\"\n",
    "real_path=dir+\"/frame_real\"\n",
    "fake_path=dir+\"/frame_fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.empty((0, 768), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(real_path):\n",
    "    img=Image.open(real_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    # if(ctr%100==0):\n",
    "    print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(fake_path):\n",
    "    img=Image.open(fake_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    # if(ctr%100==0):\n",
    "    print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(features_array)\n",
    "a=[]\n",
    "\n",
    "for i in range(33823):\n",
    "    if i<15416:\n",
    "        a.append(0)\n",
    "    else:\n",
    "        a.append(1)\n",
    "\n",
    "df['label']=a\n",
    "\n",
    "df.to_csv(\"../Data/FFEfficientFormer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"../Data/sampled_Faces/ELA_Frames\"\n",
    "real_path=dir+\"/Real\"\n",
    "fake_path=dir+\"/Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.empty((0, 768), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(real_path):\n",
    "    img=cv2.imread(real_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    if(ctr%100==0):\n",
    "        print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(fake_path):\n",
    "    img=cv2.imread(fake_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    if(ctr%100==0):\n",
    "        print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(features_array)\n",
    "df.head()\n",
    "\n",
    "a=[]\n",
    "\n",
    "for i in range(33823):\n",
    "    if i<15416:\n",
    "        a.append(0)\n",
    "    else:\n",
    "        a.append(1)\n",
    "\n",
    "df[\"label\"]=a\n",
    "\n",
    "df.to_csv(\"../Data/ffELAEfficientFormer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"../Data/Image_set2/ELA_images/train\"\n",
    "real_path=dir+\"/Real\"\n",
    "fake_path=dir+\"/Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.empty((0, 768), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(real_path):\n",
    "    img=cv2.imread(real_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    if(ctr%100==0):\n",
    "        print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=1\n",
    "for image in os.listdir(fake_path):\n",
    "    img=cv2.imread(fake_path+\"/\"+image)\n",
    "    \n",
    "    inputs = image_processor(img, return_tensors=\"pt\").to('cuda')\n",
    "    model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    features = features.to('cuda')\n",
    "    global_avg_pooling_layer = nn.AdaptiveAvgPool1d(1)  # 1D global average pooling\n",
    "    output = global_avg_pooling_layer(features.permute(0, 2, 1)).squeeze()\n",
    "    output = output.view(1, -1) \n",
    "    feat = output.cpu().detach().numpy()\n",
    "    \n",
    "    features_array = np.concatenate((features_array,feat), axis = 0)\n",
    "    if(ctr%100==0):\n",
    "        print(f\"Image {ctr} done\")\n",
    "    ctr+=1\n",
    "    del feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(features_array)\n",
    "df.head()\n",
    "\n",
    "a=[]\n",
    "\n",
    "for i in range(29736):\n",
    "    if i<14697:\n",
    "        a.append(0)\n",
    "    else:\n",
    "        a.append(1)\n",
    "\n",
    "df[\"label\"]=a\n",
    "\n",
    "df.to_csv(\"../Data/celebdfELAEfficientFormer.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
